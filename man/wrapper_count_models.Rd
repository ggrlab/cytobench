% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapper_count_models.R
\name{wrapper_count_models}
\alias{wrapper_count_models}
\title{Make hyperparameter-optimized models for all outcomes and feature sets}
\usage{
wrapper_count_models(
  df_list,
  tvt_col = "tvt",
  outdir = "res_count_models",
  dvs_potential = colnames(df_list[[1]])[1],
  ivs = colnames(df_list[[1]])[-1],
  ivs_regex = "[cC]luster",
  dvs_multiclass = c("ABO", "A_AB", "B_AB", "abo_removedAB"),
  seed = 2372876,
  hparam_n_evaluations = 1000,
  learners_classification = list(mlr3::lrn("classif.ranger", predict_type = "prob",
    predict_sets = c("train", "test"), max.depth = paradox::to_tune(2, 20), num.trees =
    paradox::to_tune(c(500, 1000, 1500, 2000)), use_weights = "error")),
  learners_regression = list(mlr3::lrn("regr.ranger", predict_sets = c("train", "test"),
    max.depth = paradox::to_tune(2, 20), num.trees = paradox::to_tune(c(500, 1000, 1500,
    2000)), use_weights = "error")),
  dv_class_positive = NULL,
  measures = NULL,
  hpoptimized_final_trainsets = c("train", "validation"),
  verbose = TRUE
)
}
\arguments{
\item{df_list}{A list of dataframes with the same OUTCOME columns but otherwise different columns are allowed. Each dataframe is used to create a task.
Only one of the dataframes is used in the final model, based on the validation performance.}

\item{tvt_col}{The column in each dataframe that defines the training, validation and test set.
Training is used to train models on each task, validation to select the best model and df of df_list.
The final model is applied to all samples. Default is "tvt".}

\item{outdir}{The directory where the results are saved. Default is "res_count_models". If NA, no results are saved.}

\item{dvs_potential}{The potential dependent variables. For each of them, one final model is trained. Default is the first column name of the first dataframe.}

\item{ivs}{The independent variables in the dataframes. Default is all columns except the first one.
If ivs_regex is given, this is ignored.}

\item{ivs_regex}{A regular expression to select the independent variables WITHIN EACH dataframe.
This is in contrast to ivs, which must be the same for all dataframes.
If given, ivs is ignored. Default is \code{"[cC]luster"} (This would fit columns like
'cluster_1', 'cluster_2', 'metaCluster_1', 'metaCluster_2', etc.).}

\item{dvs_multiclass}{Dependent variables treated as multi-class. Default: c("ABO", "A_AB", "B_AB", "abo_removedAB").}

\item{seed}{Random seed for reproducibility. Default: 2372876.}

\item{hparam_n_evaluations}{Number of random hyperparameter configurations. Default: 1000.}

\item{learners_classification}{A list of classification learners. Default is a ranger learner with 2-20 depth and 500, 1000, 1500, 2000 trees.}

\item{learners_regression}{A list of regression learners. Default is a ranger learner with 2-20 depth and 500, 1000, 1500, 2000 trees.}

\item{dv_class_positive}{A vector of positive labels for the classification tasks. If NULL, the positive label is inferred from the data.}

\item{measures}{The performance measures for the hyperparameter optimization. If NULL, the default measures are used.}

\item{hpoptimized_final_trainsets}{Sets used for final model training. Default: c("train", "validation").}

\item{verbose}{Logical. If TRUE, prints progress messages. Default: TRUE.}
}
\description{
Use the list of dataframes in df_list to create hyperparameter-optimized models for all potential dependent variables
in dvs_potential. Only one of the dataframes is used in the final model based on the validation performance.
The idea is to have a list of dataframes with different independent variables (e.g. "cluster" and "metaCluster")
and to select the best set of features based on the validation performance.

The independent variables are given either as character vector "ivs" or as a regular expression
"ivs_regex" to select the columns from \code{df_list[[1]]}.

The dvs are separated into binary, multi-class and continuous outcomes. Multi-class variables
have to be defined in dvs_multiclass.

Based on the column "tvt_col" in each dataframe, the data is split into training, validation and test set.

The training and validation set are used for hyperparameter optimization. "hparam_n_evaluations" random
hyperparameters are tested for each learner. The best model is selected according to the
default performance measures for each task type.

IMPORTANT: Only ONE of the df_list dataframes is used in the final model. Which model it
is is also selected based on the performance on the validation set.

After HP optimization, a final model is
trained on the training and validation set together.

learners_classification holds all learners for classification tasks, learners_regression for regression tasks.

The final model is then applied to all the samples together.
}
\examples{
ff_example <- example_processed()
fsom <- do_flowsom_TESTING(ff_example)
res <- flowSOM_predict(
    flowsom_result = fsom,
    flowset = flowCore::flowSet(ff_example)
)
fake_clusterings <- lapply(res[["ncells_per_x"]], function(x) {
    lapply(1:50, function(y) {
        x[1, -1] <- as.list(sample(1000, ncol(x) - 1))
        x[1, 1] <- sample(c("A", "B"), 1)
        x[["tvt"]] <- sample(c("train", "validation", "test", "prospective"), 1)
        return(x)
    }) |> do.call(what = rbind)
})
allowed_clusterings <- c("cluster", "metaCluster")
finalmodels_predictions <- wrapper_count_models(
    df_list = fake_clusterings[allowed_clusterings],
    tvt_col = "tvt",
    # outdir = file.path(outdir_base, basename(metaclustering_dir), training_device),
    outdir = local_tempdir_time(),
    dvs_potential = c("sample"),
    dvs_multiclass = c(),
    ivs_regex = "[cC]luster",
    hparam_n_evaluations = 3,
    seed = 1372873,
    learners_classification = list(
        mlr3::lrn(
            "classif.ranger",
            predict_type = "prob", predict_sets = c("train", "test"),
            max.depth = paradox::to_tune(2, 20), # minimum and maximum depth
            num.trees = paradox::to_tune(c(500, 1000, 1500, 2000)),
            importance = "impurity"
        )
    ),
    dv_class_positive = c("sample" = "B"),
    measures = mlr3::msr("classif.logloss")
)
}
\keyword{cytometry}
\keyword{models}
