% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wrapper_count_models.R
\name{wrapper_count_models}
\alias{wrapper_count_models}
\title{Make hyperparameter-optimized models for all outcomes and feature sets}
\usage{
wrapper_count_models(
  df_list,
  tvt_col = "tvt",
  outdir = "res_count_models",
  dvs_potential = colnames(df_list[[1]])[[1]],
  ivs = colnames(df_list[[1]])[[-1]],
  ivs_regex = "[cC]luster",
  dvs_multiclass = c("ABO", "A_AB", "B_AB", "abo_removedAB"),
  seed = 2372876,
  hparam_n_evaluations = 1000,
  learners_classification = list(mlr3::lrn("classif.ranger", predict_type = "prob",
    predict_sets = c("train", "test"), max.depth = paradox::to_tune(2, 20), num.trees =
    paradox::to_tune(c(500, 1000, 1500, 2000)))),
  learners_regression = list(mlr3::lrn("regr.ranger", predict_sets = c("train", "test"),
    max.depth = paradox::to_tune(2, 20), num.trees = paradox::to_tune(c(500, 1000, 1500,
    2000))))
)
}
\arguments{
\item{df_list}{A list of dataframes with the same columns. Each dataframe is used to create a task.
Only one of the dataframes is used in the final model, based on the validation performance.}

\item{tvt_col}{The column in each dataframe that defines the training, validation and test set.
Training is used to train models on each task, validation to select the best model and df of df_list.
The final model is applied to all samples. Default is "tvt".}

\item{outdir}{The directory where the results are saved. Default is "res_count_models".
If NA, no results are saved.}

\item{dvs_potential}{The potential dependent variables in the dataframes. For each of them, one final
model is trained. Default is the first column name of the first dataframe.}

\item{ivs}{The independent variables in the dataframes. Default is all columns except the first one.
If ivs_regex is given, this is ignored.}

\item{ivs_regex}{A regular expression to select the independent variables based on the first dataframe.
If given, ivs is ignored. Default is "\link{cC}luster".#}

\item{dvs_multiclass}{The dependent variables that are multi-class. Default is c("ABO", "A_AB", "B_AB", "abo_removedAB").}

\item{seed}{The seed for the random hyperparameter optimization. Default is 2372876.}

\item{hparam_n_evaluations}{The number of random hyperparameters to test for each learner. Default is 1000.}

\item{learners_classification}{A list of classification learners. Default is a ranger learner with 2-20 depth and 500, 1000, 1500, 2000 trees.}

\item{learners_regression}{A list of regression learners. Default is a ranger learner with 2-20 depth and 500, 1000, 1500, 2000 trees.}
}
\description{
Use the list of dataframes in df_list to create hyperparameter-optimized models for all potential dependent variables
in dvs_potential. Only one of the dataframes is used in the final model based on the validation performance.
The idea is to have a list of dataframes with different independent variables (e.g. "cluster" and "metaCluster")
and to select the best set of features based on the validation performance.

The independent variables are given either as character vector "ivs" or as a regular expression
"ivs_regex" to select the columns from df_list[\link{1}].

The dvs are separated into binary, multi-class and continuous outcomes. Multi-class variables
have to be defined in dvs_multiclass.

Based on the column "tvt_col" in each dataframe, the data is split into training, validation and test set.

The training and validation set are used for hyperparameter optimization. "hparam_n_evaluations" random
hyperparameters are tested for each learner. The best model is selected according to the
default performance measures for each task type.

IMPORTANT: Only ONE of the df_list dataframes is used in the final model. Which model it
is is also selected based on the performance on the validation set.

After HP optimization, a final model is
trained on the training and validation set together.

learners_classification holds all learners for classification tasks, learners_regression for regression tasks.

The final model is then applied to all the samples together.
}
